<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Embedding Providers &amp; Operations &#8212; OpenClaw Technical Documentation 2026.2.23 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=5ecbeea2" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=12dfc556" />
    <script src="../_static/documentation_options.js?v=54c96c00"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="External QMD Backend" href="qmd-backend.html" />
    <link rel="prev" title="Retrieval Pipeline" href="knowledge-retrieval.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="embedding-providers-operations">
<h1>Embedding Providers &amp; Operations<a class="headerlink" href="#embedding-providers-operations" title="Link to this heading">¶</a></h1>
<p>This page documents the embedding providers available to OpenClaw, the
auto-selection cascade, and the embedding operations that transform text
chunks into vectors for semantic search.</p>
<nav class="contents local" id="on-this-page">
<p class="topic-title">On this page</p>
<ul class="simple">
<li><p><a class="reference internal" href="#provider-table" id="id1">Provider Table</a></p></li>
<li><p><a class="reference internal" href="#auto-selection-cascade" id="id2">Auto-Selection Cascade</a></p></li>
<li><p><a class="reference internal" href="#l2-normalization" id="id3">L2 Normalization</a></p></li>
<li><p><a class="reference internal" href="#chunking" id="id4">Chunking</a></p></li>
<li><p><a class="reference internal" href="#batch-embedding" id="id5">Batch Embedding</a></p></li>
<li><p><a class="reference internal" href="#batch-failure-tracking" id="id6">Batch Failure Tracking</a></p></li>
<li><p><a class="reference internal" href="#embedding-cache" id="id7">Embedding Cache</a></p></li>
<li><p><a class="reference internal" href="#retry-and-timeout" id="id8">Retry and Timeout</a></p></li>
</ul>
</nav>
<section id="provider-table">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Provider Table</a><a class="headerlink" href="#provider-table" title="Link to this heading">¶</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 12.0%" />
<col style="width: 12.0%" />
<col style="width: 30.0%" />
<col style="width: 20.0%" />
<col style="width: 26.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Provider ID</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Default Model</p></th>
<th class="head"><p>Max Input Tokens</p></th>
<th class="head"><p>Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">local</span></code></p></td>
<td><p>Local</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">hf:ggml-org/embeddinggemma-300m-qat-q8_0-GGUF/embeddinggemma-300m-qat-Q8_0.gguf</span></code></p></td>
<td><p>N/A (model-dependent)</p></td>
<td><p>Uses <code class="docutils literal notranslate"><span class="pre">node-llama-cpp</span></code>; requires Node 22+.  Model is downloaded on
first use from Hugging Face.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">openai</span></code></p></td>
<td><p>Remote</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">text-embedding-3-small</span></code></p></td>
<td><p>8192</p></td>
<td><p>Standard OpenAI embeddings API.  Also supports <code class="docutils literal notranslate"><span class="pre">text-embedding-3-large</span></code>
and <code class="docutils literal notranslate"><span class="pre">text-embedding-ada-002</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">gemini</span></code></p></td>
<td><p>Remote</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">gemini-embedding-001</span></code></p></td>
<td><p>2048 (<code class="docutils literal notranslate"><span class="pre">text-embedding-004</span></code>)</p></td>
<td><p>Google AI Studio / Vertex AI.  Supports API key rotation.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">voyage</span></code></p></td>
<td><p>Remote</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">voyage-4-large</span></code></p></td>
<td><p>32000 (<code class="docutils literal notranslate"><span class="pre">voyage-3</span></code>, <code class="docutils literal notranslate"><span class="pre">voyage-code-3</span></code>)</p></td>
<td><p>Voyage AI embeddings with batch API support.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mistral</span></code></p></td>
<td><p>Remote</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mistral-embed</span></code></p></td>
<td><p>N/A</p></td>
<td><p>Mistral AI embeddings endpoint.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="auto-selection-cascade">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Auto-Selection Cascade</a><a class="headerlink" href="#auto-selection-cascade" title="Link to this heading">¶</a></h2>
<p>When <code class="docutils literal notranslate"><span class="pre">provider</span></code> is set to <code class="docutils literal notranslate"><span class="pre">&quot;auto&quot;</span></code> (the default), OpenClaw tries each
provider in sequence until one succeeds:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>1. local    -- only if a local model file already exists on disk
2. openai   -- if OPENAI_API_KEY is available
3. gemini   -- if GEMINI_API_KEY or Vertex credentials are available
4. voyage   -- if VOYAGE_API_KEY is available
5. mistral  -- if MISTRAL_API_KEY is available
</pre></div>
</div>
<p><strong>Rules:</strong></p>
<ul class="simple">
<li><p><strong>Local is tried first</strong> only if <code class="docutils literal notranslate"><span class="pre">canAutoSelectLocal()</span></code> returns <code class="docutils literal notranslate"><span class="pre">true</span></code>
(the configured <code class="docutils literal notranslate"><span class="pre">modelPath</span></code> points to an existing file on disk, not a
<code class="docutils literal notranslate"><span class="pre">hf:</span></code> or <code class="docutils literal notranslate"><span class="pre">https:</span></code> URL).</p></li>
<li><p>Each remote provider is tried by calling <code class="docutils literal notranslate"><span class="pre">createProvider()</span></code>.  If it
throws a “missing API key” error, the cascade continues to the next.</p></li>
<li><p>If a non-auth error occurs (e.g. network failure), it is thrown immediately
(no further cascade).</p></li>
<li><p><strong>If all providers fail</strong> with missing-key errors, the system enters
<strong>FTS-only mode</strong> (<code class="docutils literal notranslate"><span class="pre">provider:</span> <span class="pre">null</span></code>).  Memory search still works via
keyword matching.</p></li>
</ul>
<p><strong>Fallback configuration:</strong></p>
<p>A <code class="docutils literal notranslate"><span class="pre">fallback</span></code> setting allows specifying a backup provider.  If the primary
fails:</p>
<ol class="arabic simple">
<li><p>Try the primary provider.</p></li>
<li><p>If it fails, try the <code class="docutils literal notranslate"><span class="pre">fallback</span></code> provider.</p></li>
<li><p>If both fail with auth errors, enter FTS-only mode.</p></li>
<li><p>If a non-auth error occurs on fallback, throw.</p></li>
</ol>
<p>At runtime, if embedding calls fail with errors matching
<code class="docutils literal notranslate"><span class="pre">/embedding|embeddings|batch/i</span></code>, the sync layer can dynamically activate the
fallback provider and trigger a full reindex.</p>
</section>
<section id="l2-normalization">
<h2><a class="toc-backref" href="#id3" role="doc-backlink">L2 Normalization</a><a class="headerlink" href="#l2-normalization" title="Link to this heading">¶</a></h2>
<p>Source: <code class="docutils literal notranslate"><span class="pre">src/memory/embeddings.ts</span></code></p>
<p>All embedding vectors (from any provider) are L2-normalized before storage:</p>
<div class="highlight-typescript notranslate"><div class="highlight"><pre><span></span><span class="kd">function</span><span class="w"> </span><span class="nx">sanitizeAndNormalizeEmbedding</span><span class="p">(</span><span class="nx">vec</span><span class="o">:</span><span class="w"> </span><span class="kt">number</span><span class="p">[])</span><span class="o">:</span><span class="w"> </span><span class="kt">number</span><span class="p">[]</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kd">const</span><span class="w"> </span><span class="nx">sanitized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">vec</span><span class="p">.</span><span class="nx">map</span><span class="p">(</span><span class="nx">v</span><span class="w"> </span><span class="p">=&gt;</span><span class="w"> </span><span class="nb">Number</span><span class="p">.</span><span class="nb">isFinite</span><span class="p">(</span><span class="nx">v</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="kt">0</span><span class="p">);</span>
<span class="w">  </span><span class="kd">const</span><span class="w"> </span><span class="nx">magnitude</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">Math</span><span class="p">.</span><span class="nx">sqrt</span><span class="p">(</span>
<span class="w">    </span><span class="nx">sanitized</span><span class="p">.</span><span class="nx">reduce</span><span class="p">((</span><span class="nx">sum</span><span class="p">,</span><span class="w"> </span><span class="nx">v</span><span class="p">)</span><span class="w"> </span><span class="p">=&gt;</span><span class="w"> </span><span class="nx">sum</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nx">v</span><span class="p">,</span><span class="w"> </span><span class="mf">0</span><span class="p">)</span>
<span class="w">  </span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="nx">magnitude</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">1e-10</span><span class="p">)</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="nx">sanitized</span><span class="p">;</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="nx">sanitized</span><span class="p">.</span><span class="nx">map</span><span class="p">(</span><span class="nx">v</span><span class="w"> </span><span class="p">=&gt;</span><span class="w"> </span><span class="nx">v</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nx">magnitude</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Normalization ensures that cosine similarity is equivalent to dot product,
and that the <code class="docutils literal notranslate"><span class="pre">vec_distance_cosine</span></code> function in sqlite-vec produces
consistent results regardless of provider-specific output scaling.</p>
</section>
<section id="chunking">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Chunking</a><a class="headerlink" href="#chunking" title="Link to this heading">¶</a></h2>
<p>Source: <code class="docutils literal notranslate"><span class="pre">src/memory/internal.ts</span></code> (<code class="docutils literal notranslate"><span class="pre">chunkMarkdown</span></code>)</p>
<p>Before embedding, Markdown files are split into chunks:</p>
<p><strong>Default parameters:</strong></p>
<ul class="simple">
<li><p><strong>Tokens:</strong> 400 (<code class="docutils literal notranslate"><span class="pre">DEFAULT_CHUNK_TOKENS</span></code>)</p></li>
<li><p><strong>Overlap:</strong> 80 (<code class="docutils literal notranslate"><span class="pre">DEFAULT_CHUNK_OVERLAP</span></code>)</p></li>
</ul>
<p><strong>Algorithm:</strong></p>
<ol class="arabic simple">
<li><p>Split the file into lines.</p></li>
<li><p>Accumulate lines into a current chunk until <code class="docutils literal notranslate"><span class="pre">maxChars</span></code> (tokens * 4)
is exceeded.</p></li>
<li><p>Flush the chunk, recording <code class="docutils literal notranslate"><span class="pre">startLine</span></code> and <code class="docutils literal notranslate"><span class="pre">endLine</span></code>.</p></li>
<li><p>Carry over the last <code class="docutils literal notranslate"><span class="pre">overlapChars</span></code> (overlap * 4) characters worth of
lines into the next chunk for context continuity.</p></li>
<li><p>Each chunk gets a SHA-256 <code class="docutils literal notranslate"><span class="pre">hash</span></code> of its text for change detection.</p></li>
</ol>
<p>For session files, <code class="docutils literal notranslate"><span class="pre">remapChunkLines()</span></code> adjusts the chunk line numbers
using the <code class="docutils literal notranslate"><span class="pre">lineMap</span></code> to point back to the original JSONL line numbers.</p>
</section>
<section id="batch-embedding">
<h2><a class="toc-backref" href="#id5" role="doc-backlink">Batch Embedding</a><a class="headerlink" href="#batch-embedding" title="Link to this heading">¶</a></h2>
<p>Source: <code class="docutils literal notranslate"><span class="pre">src/memory/manager-embedding-ops.ts</span></code> and 14 <code class="docutils literal notranslate"><span class="pre">batch-*.ts</span></code> files.</p>
<p><strong>Batch files in ``src/memory/``:</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 40.0%" />
<col style="width: 60.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>File</p></th>
<th class="head"><p>Purpose</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">batch-runner.ts</span></code></p></td>
<td><p>Generic batch orchestration (polling, concurrency, timeouts)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">batch-openai.ts</span></code></p></td>
<td><p>OpenAI batch embedding API integration</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">batch-gemini.ts</span></code></p></td>
<td><p>Gemini batch embedding (<code class="docutils literal notranslate"><span class="pre">asyncBatchEmbedContent</span></code>)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">batch-voyage.ts</span></code></p></td>
<td><p>Voyage batch embedding API</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">batch-http.ts</span></code></p></td>
<td><p>HTTP utilities for batch file upload/download</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">batch-upload.ts</span></code></p></td>
<td><p>JSONL file creation and upload for OpenAI batch API</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">batch-output.ts</span></code></p></td>
<td><p>Output parsing for completed batch jobs</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">batch-utils.ts</span></code></p></td>
<td><p>Shared utilities (ID generation, status polling)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">batch-provider-common.ts</span></code></p></td>
<td><p>Provider-agnostic batch logic</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">batch-error-utils.ts</span></code></p></td>
<td><p>Error classification (retryable vs. fatal)</p></td>
</tr>
</tbody>
</table>
<p><strong>How batch embedding works:</strong></p>
<ol class="arabic simple">
<li><p>Chunks are grouped into batches by estimated byte size
(<code class="docutils literal notranslate"><span class="pre">EMBEDDING_BATCH_MAX_TOKENS</span> <span class="pre">=</span> <span class="pre">8000</span></code>).</p></li>
<li><p>Cached embeddings are loaded first; only uncached chunks are sent.</p></li>
<li><p>For OpenAI: JSONL batch files are uploaded to the batch API endpoint.</p></li>
<li><p>For Gemini: <code class="docutils literal notranslate"><span class="pre">asyncBatchEmbedContent</span></code> is called with content parts.</p></li>
<li><p>For Voyage: Standard batch embedding with polling.</p></li>
<li><p>Results are polled with configurable concurrency, interval, and timeout.</p></li>
<li><p>Completed embeddings are written to the embedding cache.</p></li>
</ol>
</section>
<section id="batch-failure-tracking">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Batch Failure Tracking</a><a class="headerlink" href="#batch-failure-tracking" title="Link to this heading">¶</a></h2>
<p>The system automatically disables batch embedding after repeated failures
to prevent cascading errors:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>BATCH_FAILURE_LIMIT = 2
</pre></div>
</div>
<ul class="simple">
<li><p>Each batch failure increments <code class="docutils literal notranslate"><span class="pre">batchFailureCount</span></code>.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">batchFailureCount</span> <span class="pre">&gt;=</span> <span class="pre">BATCH_FAILURE_LIMIT</span></code> (2), batch mode is
disabled for the remainder of the session.</p></li>
<li><p>The system falls back to sequential non-batch embedding.</p></li>
<li><p>On a successful batch, the failure count resets to 0.</p></li>
<li><p>Special case: <code class="docutils literal notranslate"><span class="pre">asyncBatchEmbedContent</span> <span class="pre">not</span> <span class="pre">available</span></code> immediately
disables batch (<code class="docutils literal notranslate"><span class="pre">forceDisable</span> <span class="pre">=</span> <span class="pre">true</span></code>).</p></li>
<li><p>A serialized lock (<code class="docutils literal notranslate"><span class="pre">batchFailureLock</span></code>) prevents race conditions when
multiple batch operations complete concurrently.</p></li>
</ul>
<p><strong>Status reporting:</strong></p>
<p>The <code class="docutils literal notranslate"><span class="pre">batch</span></code> field in <code class="docutils literal notranslate"><span class="pre">MemoryProviderStatus</span></code> reports:</p>
<div class="highlight-typescript notranslate"><div class="highlight"><pre><span></span><span class="nx">batch</span><span class="o">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nx">enabled</span><span class="o">:</span><span class="w"> </span><span class="kt">boolean</span><span class="p">;</span><span class="w">     </span><span class="c1">// current state</span>
<span class="w">  </span><span class="nx">failures</span><span class="o">:</span><span class="w"> </span><span class="kt">number</span><span class="p">;</span><span class="w">     </span><span class="c1">// current failure count</span>
<span class="w">  </span><span class="nx">limit</span><span class="o">:</span><span class="w"> </span><span class="kt">number</span><span class="p">;</span><span class="w">        </span><span class="c1">// 2 (the disable threshold)</span>
<span class="w">  </span><span class="nx">wait</span><span class="o">:</span><span class="w"> </span><span class="kt">boolean</span><span class="p">;</span><span class="w">        </span><span class="c1">// wait for batch completion before search?</span>
<span class="w">  </span><span class="nx">concurrency</span><span class="o">:</span><span class="w"> </span><span class="kt">number</span><span class="p">;</span><span class="w">  </span><span class="c1">// max concurrent batch polls</span>
<span class="w">  </span><span class="nx">pollIntervalMs</span><span class="o">:</span><span class="w"> </span><span class="kt">number</span><span class="p">;</span>
<span class="w">  </span><span class="nx">timeoutMs</span><span class="o">:</span><span class="w"> </span><span class="kt">number</span><span class="p">;</span>
<span class="w">  </span><span class="nx">lastError?</span><span class="o">:</span><span class="w"> </span><span class="kt">string</span><span class="p">;</span>
<span class="w">  </span><span class="nx">lastProvider?</span><span class="o">:</span><span class="w"> </span><span class="kt">string</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="embedding-cache">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Embedding Cache</a><a class="headerlink" href="#embedding-cache" title="Link to this heading">¶</a></h2>
<p>The embedding cache (<code class="docutils literal notranslate"><span class="pre">embedding_cache</span></code> table) stores computed embeddings
keyed by <code class="docutils literal notranslate"><span class="pre">(provider,</span> <span class="pre">model,</span> <span class="pre">provider_key,</span> <span class="pre">hash)</span></code>:</p>
<ul class="simple">
<li><p>On index, the cache is checked first.  Cache hits skip the embedding API
call entirely.</p></li>
<li><p>On reindex, the cache is seeded from the old database into the new temp
database via <code class="docutils literal notranslate"><span class="pre">seedEmbeddingCache()</span></code>.</p></li>
<li><p>Cache pruning occurs after reindex when the entry count exceeds
<code class="docutils literal notranslate"><span class="pre">maxEntries</span></code> – oldest entries (by <code class="docutils literal notranslate"><span class="pre">updated_at</span></code>) are deleted.</p></li>
</ul>
<p>This is particularly valuable for:</p>
<ul class="simple">
<li><p><strong>Provider switches:</strong> When switching from OpenAI to Gemini, only the
uncached chunks need re-embedding.</p></li>
<li><p><strong>Full reindex:</strong> The safe reindex (temp DB swap) preserves the cache
so unchanged chunks are not re-embedded.</p></li>
<li><p><strong>Workspace restores:</strong> If the database is deleted but files are unchanged,
the first sync re-embeds everything but the cache is rebuilt for future use.</p></li>
</ul>
</section>
<section id="retry-and-timeout">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Retry and Timeout</a><a class="headerlink" href="#retry-and-timeout" title="Link to this heading">¶</a></h2>
<p>Source: <code class="docutils literal notranslate"><span class="pre">src/memory/manager-embedding-ops.ts</span></code></p>
<p><strong>Retry logic</strong> (<code class="docutils literal notranslate"><span class="pre">embedBatchWithRetry</span></code>):</p>
<ul class="simple">
<li><p>Max attempts: 3 (<code class="docutils literal notranslate"><span class="pre">EMBEDDING_RETRY_MAX_ATTEMPTS</span></code>)</p></li>
<li><p>Base delay: 500ms with exponential backoff and 20% jitter</p></li>
<li><p>Max delay cap: 8000ms</p></li>
<li><p>Retryable errors: <code class="docutils literal notranslate"><span class="pre">rate_limit</span></code>, <code class="docutils literal notranslate"><span class="pre">too</span> <span class="pre">many</span> <span class="pre">requests</span></code>, <code class="docutils literal notranslate"><span class="pre">429</span></code>,
<code class="docutils literal notranslate"><span class="pre">resource</span> <span class="pre">has</span> <span class="pre">been</span> <span class="pre">exhausted</span></code>, <code class="docutils literal notranslate"><span class="pre">5xx</span></code>, <code class="docutils literal notranslate"><span class="pre">cloudflare</span></code></p></li>
</ul>
<p><strong>Timeout values:</strong></p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Operation</p></th>
<th class="head"><p>Local</p></th>
<th class="head"><p>Remote</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Query (single embedding)</p></td>
<td><p>5 minutes</p></td>
<td><p>60 seconds</p></td>
</tr>
<tr class="row-odd"><td><p>Batch (multiple embeddings)</p></td>
<td><p>10 minutes</p></td>
<td><p>2 minutes</p></td>
</tr>
</tbody>
</table>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">OpenClaw Technical Documentation</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../architecture/index.html">Architecture Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../orchestration/index.html">Orchestration Overview</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Knowledge System Overview</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#big-picture">Big Picture</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#knowledge-lifecycle">Knowledge Lifecycle</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#dual-backend-architecture">Dual-Backend Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#graceful-degradation-chain">Graceful Degradation Chain</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#class-hierarchy">Class Hierarchy</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#memory-v2-research-direction">Memory v2 Research Direction</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="memory-architecture.html">Architecture Deep-Dive</a></li>
<li class="toctree-l3"><a class="reference internal" href="knowledge-creation.html">How Knowledge is Created</a></li>
<li class="toctree-l3"><a class="reference internal" href="knowledge-storage.html">SQLite Storage Schema</a></li>
<li class="toctree-l3"><a class="reference internal" href="knowledge-retrieval.html">Retrieval Pipeline</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Embedding Providers &amp; Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="qmd-backend.html">External QMD Backend</a></li>
<li class="toctree-l3"><a class="reference internal" href="memory-tools.html">Memory Tools</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../skills/index.html">Skills System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../channels/index.html">Channel System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gateway/index.html">Gateway Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plugins/index.html">Plugin System</a></li>
<li class="toctree-l1"><a class="reference internal" href="../infrastructure/index.html">Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">Knowledge System Overview</a><ul>
      <li>Previous: <a href="knowledge-retrieval.html" title="previous chapter">Retrieval Pipeline</a></li>
      <li>Next: <a href="qmd-backend.html" title="next chapter">External QMD Backend</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024-2026, OpenClaw Contributors.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../_sources/knowledge/embeddings.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>